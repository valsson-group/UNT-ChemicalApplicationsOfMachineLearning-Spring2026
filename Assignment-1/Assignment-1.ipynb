{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "generative_ai_disabled": true,
      "authorship_tag": "ABX9TyOYlsI1WzO79hD6vy6G/8Mq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valsson-group/UNT-ChemicalApplicationsOfMachineLearning-Spring2026/blob/main/Assignment-1/Assignment-1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chemical Applications of Machine Learning (CHEM 4930/5610) - Spring 2026\n",
        "\n",
        "### Assignment 1 - Deadline 1/20/2026\n",
        "Points 10\n",
        "\n",
        "In this assignments, you will perform three different tasks on simple datasets.\n",
        "\n",
        "#### General Comments\n",
        "All figures and graph should have approriate labels on the two axis, and should include a legend with appropriate labels of the different plots.\n",
        "\n",
        "When working with multiple datasets, avoid doing things by hand and instead try to use for loops.\n",
        "\n",
        "The notebook should be return in working format. That is, I should be able to reset all the output and re-run all the cells and get the same results as you obtained."
      ],
      "metadata": {
        "id": "mCl_XQfPCKtb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Student Name**: Add your name here\n",
        "\n",
        "**AI usage statement:**\n",
        "Here you should give a statement about any usage of AI tools to assist you with the coding."
      ],
      "metadata": {
        "id": "Putv2cBPVon5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1 - 2 points\n",
        "\n",
        "Create a python functions that convert Celsius to Fahrenheit and vice versa.\n",
        "\n",
        "Create three version:\n",
        "- A) One should take in a number and return the converted number as a variable that one can save into variable.\n",
        "- B) One should take in a number and print out the answer in a nice format\n",
        "- C) One should take in a number and return a string with the answer in a nice format.\n",
        "\n",
        "Show examples that show how the functions work."
      ],
      "metadata": {
        "id": "-5tHOacufv3F"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tHzH30mufwos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2 - 4 points\n",
        "\n",
        "In this task we consider a dataset that consisist of 10 time series that are obtained from a stochastic process given by [autoregressive model](https://en.wikipedia.org/wiki/Autoregressive_model) of order 1. Autoregressive models are stochastic process that includes memory effects.\n",
        "\n",
        "All the 10 time series are independent runs obtained from an autoregressive model with same set of parameters, which are the mean $\\mu$, the standard deviation $\\sigma$, and the $\\varphi_{1}$ parameter.   \n",
        "\n",
        "The data files have the names `Dataset-##.data` where `##` is a number from 1 to 10. Number is given by two digits and padded by zeros, so that files names are `Dataset-01.data`, `Dataset-02.data`, etc.\n",
        "\n",
        "There is a Bash script below that takes care of downloading all the files\n",
        "\n",
        "The data files have two columns, the first column is the time and the second column is the time series.\n",
        "\n",
        "- A) Plot all the time series, either on the same graph, or on seperate graphs. If you plot them on seperate graphs, you must ensure that the y-axis is the same for all the graph. If you plot all the time series on the same graph, you can try to plot only every $N$ data point if the graph is too crowded.\n",
        "- B) For the first dataset `Dataset-01.data`, on the same graph, plot a discrete histogram and a kernel density estimation (KDE) using Seaborn. Try different values for the number of bins in the discrete histogram. Adjust the `bw_adjust` parameter of the `seaborn.kdeplot(..)` function to find a good value that fits the data and the discrete histogram.\n",
        "- C) For all the 10 time series, make a KDE plot with all on the same graph. Employ the optimal `bw_adjust` value from B).\n",
        "- D) Calculate the average and standard deviation for the different time series and show the results in a nice text format.\n",
        "\n",
        "- Optional for 1 point: Create a plot where you present the average and standard deviation in a graphical format. The x-axis should be the data file number. The standard deviation should be presented as an error bar. Can you deduce what is the mean $\\mu$ value of the autoregressive model?\n"
      ],
      "metadata": {
        "id": "21OlZAEAEQXj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bash script to download all the dataset. Don't worry if you don't understand it\n",
        "%%bash\n",
        "\n",
        "url=\"https://raw.githubusercontent.com/valsson-group/UNT-ChemicalApplicationsOfMachineLearning-Spring2026/refs/heads/main/Assignment-1/Task-2\"\n",
        "dataset_filename=\"Task-2_Dataset-\"\n",
        "dataset_extension=\"data\"\n",
        "\n",
        "rm -f ${dataset_filename}*\n",
        "for i in `seq 1 10`;\n",
        "do\n",
        "  i2=`echo ${i} | awk '{ printf(\"%02d\\n\", $1) }'`\n",
        "  wget ${url}/${dataset_filename}${i2}.${dataset_extension} &> /dev/null\n",
        "done\n",
        "\n",
        "ls"
      ],
      "metadata": {
        "id": "jsAnkL2SEP9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PLEPeyqIVcRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3 - 4 points\n",
        "\n",
        "A common practice in machine learning is to preprocess data or features by whitening the data (or normalizing it) so that the mean of the data is 0 and the variance (and therefore also standard deviation) is 1. This can be achived with the following transformation\n",
        "\n",
        "$$\\tilde{x}_i = \\frac{x_i-\\langle x \\rangle}{\\sigma_{x}}$$\n",
        "\n",
        "where $x$ is is the original data, $\\langle x \\rangle$ is the sample mean/average, and $\\sigma_{x}$ is the standard deviation. The resultsing transformed data $\\tilde{x}$ will then have a mean of 0 and standard deviation of 1.\n",
        "\n",
        "- A) Create a python function that takes data in the form of a numpy array and returns an numpy array with the whitened/normalized data. Use one of the time series from Task 2 to show that the function does what it should do.\n",
        "- B) For all 10 time series from Task 2, whiten/normalize that data and make a time series plot and a KDE plot where all 10 time series are shown together.\n",
        "\n",
        "- Optional for 1 point: For all 10 time series, write out the whiten/normalized data to new text files. The files should have the same format as the original data files with the first column being the time and the second column being the whiten/normalized time series. The data files should include a header as the original files. You should add a suffix to the filenames to somehow indicate that they include whiten/normalized data."
      ],
      "metadata": {
        "id": "gBs_74IOQiuv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbMM1zTTBvge"
      },
      "outputs": [],
      "source": []
    }
  ]
}