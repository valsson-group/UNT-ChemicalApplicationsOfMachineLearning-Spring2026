{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "generative_ai_disabled": true,
      "authorship_tag": "ABX9TyN79nXF/RRSoo3sF8fKfLHa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valsson-group/UNT-ChemicalApplicationsOfMachineLearning-Spring2026/blob/main/Examples_scikit-learn/sklearn_linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear regression using scikit-learn\n",
        "\n",
        "This notebook shows how to perform linear regression using scikit-learn."
      ],
      "metadata": {
        "id": "0XhkgUTYNL66"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWmaAiYjZRRy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we generate a dataset $(x,y)$ of $N$ samples given by\n",
        "$$\n",
        "y = \\beta_1 x + \\beta_0 + \\epsilon\n",
        "$$\n",
        "where $\\epsilon$ is a random number taken from a Normal distribution with mean 0 and some standard deviation $\\sigma$.\n",
        "\n",
        "Thus, this is a model with linear relationship between $x$ and $y$, but with a random noise component, so the dataset will not have linear relationship. The magnitude of standard deviation $\\sigma$ will determine how much the dataset will deviate from true linear relationship."
      ],
      "metadata": {
        "id": "lhNAe-Y5NZnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a ranomd number generator.\n",
        "# This is the recommended way to use randon number in numpy.\n",
        "\n",
        "rng = np.random.default_rng()\n",
        "\n",
        "x_range_min = 1.0\n",
        "x_range_max = 60.0\n",
        "\n",
        "beta_1=2.54\n",
        "beta_0=10.05\n",
        "random_sigma=25\n",
        "NumberOfValues=50\n",
        "\n",
        "# sample x values randomly uniformaly from the range given by [x_range_min,x_range_max]\n",
        "# this will give a numpy array of NumberOfValues\n",
        "x = rng.uniform(low=x_range_min, high=x_range_max, size=NumberOfValues)\n",
        "\n",
        "# generate a numpy array of random values from a normal distrubution\n",
        "# with mean of 0 and standard deviation given by random_sigma\n",
        "noise = rng.normal(loc=0.0, scale=random_sigma, size=x.size)\n",
        "\n",
        "# calculate the y values from the x values and the noise ter,\n",
        "y = beta_1 *x + beta_0 + noise\n",
        "\n",
        "\n",
        "print(\"x values\")\n",
        "print(x)\n",
        "print(\"----------\")\n",
        "\n",
        "print(\"y values\")\n",
        "print(y)\n",
        "print(\"----------\")\n",
        "\n",
        "plt.plot(x,y,'.')\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Note that due to the random noise random noise component\n",
        "# you will get a different results each time.\n",
        "\n",
        "# If you want to obtain reproducable results that are identical\n",
        "# each time, you can initialize the random number generator\n",
        "# with a given random seed (that should be a postive integer)\n",
        "# by using rng = np.random.default_rng(seed=__SEED__), where\n",
        "# __SEED__ is some number that you choose.\n",
        "\n",
        "# If no random seed is given, then the random seed is selected\n",
        "# randomly.\n"
      ],
      "metadata": {
        "id": "os3ZjwD8ZZ9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we split the dataset into a training and test sets with a 70/30 split\n",
        "# using random selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30)\n",
        "\n",
        "# This is just to show the sizes of the sets, this is not normally needed\n",
        "print(\"Size\")\n",
        "print(\"- Full: {:d}\".format(x.size))\n",
        "print(\"- Training: {:d}\".format(x_train.size))\n",
        "print(\"- Test: {:d}\".format(x_test.size))\n",
        "\n",
        "# plot the split\n",
        "plt.plot(x_train,y_train,'.',label=\"Training set\")\n",
        "plt.plot(x_test,y_test,'.',label=\"Test set\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Again, each time you run, you will get different results.\n",
        "# you can add the parameter random_state=__SEED__, e.g.,\n",
        "# train_test_split(x,y, test_size=0.30, random_state=__SEED__)"
      ],
      "metadata": {
        "id": "VKPk_NAObPFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we perform the linear regression using\n",
        "# the LinearRegression() function\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# create a new LinearRegression() object\n",
        "linear_reg = LinearRegression()\n",
        "\n",
        "# Perform the fit to the training set.\n",
        "# Here, you need to use the reshape(-1,1) function\n",
        "# to put the data into the right shape for scikit-learn\n",
        "linear_reg.fit(x_train.reshape(-1, 1),y_train.reshape(-1, 1))\n",
        "\n"
      ],
      "metadata": {
        "id": "Gey8L_V_cgor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can get the linear coefficent using linear_reg.coef_ variable\n",
        "# that is a variable of the LinearRegression() object linear_reg.\n",
        "# We can do the same for the intercept using linear_reg.intercept_.\n",
        "# Note that both are arrays so we need to use [0] to get the first value\n",
        "# (and only value in this case).\n",
        "\n",
        "print(\"Fitted parameters\")\n",
        "print(\"- Linear Coefficent: {:.4f}\".format(linear_reg.coef_[0][0]))\n",
        "print(\"- Intercept: {:.4f}\".format(linear_reg.intercept_[0]))"
      ],
      "metadata": {
        "id": "Do3-iem1dCPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can get the R^2 or coefficient of determination value using the\n",
        "# score() function. You can do this either for the training or the test dataset.\n",
        "# The R^2 value is in the range [0,1] and a higher value means a better fit.\n",
        "\n",
        "r2_coefficient_train = linear_reg.score(x_train.reshape(-1,1),y_train.reshape(-1,1))\n",
        "r2_coefficient_test  = linear_reg.score(x_test.reshape(-1,1),y_test.reshape(-1,1))\n",
        "\n",
        "print(\"Coefficient of determination / R^2\")\n",
        "print(\"- Training Dataset: {:.4f}\".format(r2_coefficient_train))\n",
        "print(\"- Test Dataset:     {:.4f}\".format(r2_coefficient_test))"
      ],
      "metadata": {
        "id": "K8rxqPxHdusc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we create a plot showing the fit as a line\n",
        "\n",
        "# we first create a dense grind in range [x_range_min,x_range_max]\n",
        "x_predict_grid = np.linspace(x_range_min,x_range_max,1000)\n",
        "\n",
        "# then calculate the y values predicted by the linear regression\n",
        "# model using the .predict function.\n",
        "y_predict_grid = linear_reg.predict(x_predict_grid.reshape(-1,1))\n",
        "\n",
        "# plot dataset as points\n",
        "plt.plot(x_train,y_train,'.',label=\"Training set\")\n",
        "plt.plot(x_test,y_test,'.',label=\"Test set\")\n",
        "\n",
        "# plot linear fit as a line\n",
        "plt.plot(x_predict_grid,y_predict_grid,'-',label=\"Linear Regression\",linewidth=3.0)\n",
        "\n",
        "# add a text to plot to show the R^2 values\n",
        "# note that the x,y coordiantes are given in the coordinate\n",
        "# system of the data.\n",
        "# In the text string we use the \"\\n\" character that is\n",
        "# special character to indicate a new line.\n",
        "plt.text(x=1.0, y=140.0,\n",
        "         s=\"$R^2$\\nTrain: {:.3f}\\nTest:  {:.3f}\".format(r2_coefficient_train,r2_coefficient_test),\n",
        "         fontsize=10)\n",
        "\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "\n",
        "# this is to add x=0 line and a y=0 line\n",
        "ax = plt.gca()\n",
        "ax.axvline(x=0, color='black', linestyle='--', linewidth=0.5)\n",
        "ax.axhline(y=0, color='black', linestyle='--', linewidth=0.5)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zUVfbbcmeXZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eMONlzJEZ9CT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we perform a linear regression using the RANSAC method\n",
        "# that allows for handeling outliers. It automatically detects\n",
        "# possible outliers and does the linear regression fit only using the inliers.\n",
        "\n",
        "# References\n",
        "# https://scikit-learn.org/stable/modules/linear_model.html#ransac-regression\n",
        "# https://scikit-learn.org/stable/auto_examples/linear_model/plot_ransac.html#sphx-glr-auto-examples-linear-model-plot-ransac-py\n",
        "\n",
        "\n",
        "from sklearn.linear_model import RANSACRegressor\n",
        "\n",
        "ransac_reg = RANSACRegressor()\n",
        "\n",
        "# Here we will do the fit on the full (x,y) dataset\n",
        "ransac_reg.fit(x.reshape(-1, 1),y.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "8YuV4A5meo9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_coefficient_ransac = ransac_reg.score(x.reshape(-1,1),y.reshape(-1,1))\n",
        "\n",
        "print(\"Coefficient of determination / R^2:     {:.4f}\".format(r2_coefficient_ransac))\n",
        "print(\"Fitted parameters\")\n",
        "print(\"- Linear Coefficent: {:.4f}\".format(ransac_reg.estimator_.coef_[0][0]))\n",
        "print(\"- Intercept: {:.4f}\".format(ransac_reg.estimator_.intercept_[0]))"
      ],
      "metadata": {
        "id": "PltBdDUHi25a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can get a \"mask\" for inliers by using .inlier_mask\n",
        "# this is a array of the same size as x and y with boolean\n",
        "# elements that are True if the corresponding element is an\n",
        "# inlier.\n",
        "inlier_mask = ransac_reg.inlier_mask_\n",
        "\n",
        "# we can get the corresponding outlier mask by using\n",
        "# np.logical_mask() function\n",
        "outlier_mask = np.logical_not(inlier_mask)\n",
        "\n",
        "print(\"inlier mask\")\n",
        "print(inlier_mask)\n",
        "print(\"---------\")\n",
        "\n",
        "print(\"outlier mask\")\n",
        "print(outlier_mask)\n",
        "print(\"---------\")\n",
        "\n",
        "print(\"Number of outliers: {:3d}\".format(np.sum(outlier_mask)))"
      ],
      "metadata": {
        "id": "dButzg7YbHFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the predicted fit for plotting\n",
        "x_ransac_predict_grid = np.linspace(x_range_min,x_range_max,1000)\n",
        "y_ransac_predict_grid = ransac_reg.predict(x_ransac_predict_grid.reshape(-1,1))\n",
        "\n",
        "# plot inliers and outliers\n",
        "plt.plot(x[inlier_mask],y[inlier_mask],'.',label=\"Inliers\")\n",
        "plt.plot(x[outlier_mask],y[outlier_mask],'.',label=\"Outliers\")\n",
        "\n",
        "# plot the normal linear regression from before\n",
        "plt.plot(x_predict_grid,y_predict_grid,'-',label=\"Linear Regression\",linewidth=3.0)\n",
        "\n",
        "# plot the RANSAC regression\n",
        "plt.plot(x_ransac_predict_grid,y_ransac_predict_grid,'-',label=\"RANSAC Regression\",linewidth=3.0)\n",
        "\n",
        "plt.text(x=1.0, y=120,\n",
        "         s=\"$R^2$\\nTrain: {:.3f}\\nTest: {:.3f}\\nRANSAC: {:.3f}\".format(r2_coefficient_train,r2_coefficient_test,r2_coefficient_ransac),\n",
        "         fontsize=10)\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "\n",
        "ax = plt.gca()\n",
        "ax.axvline(x=0, color='black', linestyle='--', linewidth=0.5)\n",
        "ax.axhline(y=0, color='black', linestyle='--', linewidth=0.5)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mPG-gdgwieqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You should try to repeat the linear regression by changing the parameters\n",
        "used to generate the $(x,y)$ dataset, for example increasing the number of\n",
        "samples, or increasing the standard deviation $\\sigma$ in the noise term so there is more uncertainty.  "
      ],
      "metadata": {
        "id": "F6Lp_dVjcfCR"
      }
    }
  ]
}