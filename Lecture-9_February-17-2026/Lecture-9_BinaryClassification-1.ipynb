{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "generative_ai_disabled": true,
      "authorship_tag": "ABX9TyNjT7bGDNI+sVcrS4NRIStc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valsson-group/UNT-ChemicalApplicationsOfMachineLearning-Spring2026/blob/main/Lecture-9_February-17-2026/Lecture-9_BinaryClassification-1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lecture 9 - Binary Classification\n",
        "\n",
        "Here, we are going to take the first step into supervised learning and consider a classifcation problem.\n",
        "\n",
        "We will consider data from this paper:\n",
        "- Enhancing Permeability Prediction of Heterobifunctional Degraders Using Machine Learning and Metadynamics-Informed 3D Molecular Descriptors - [DOI:10.1021/acs.jcim.5c01600](doi.org/10.1021/acs.jcim.5c01600)\n",
        "\n",
        "Where the authors consider the Permeability of so-called PROTAC compounds that are large and flexible molecules used in Targeted Protein Degradation.\n",
        "\n",
        "All the dataset used in the paper, and the code use to obtain the results are given in this following Github repository:\n",
        "- https://github.com/brykimjh/degrader-permeability-ml3d-metaD  \n",
        "\n",
        "The specfic dataset that we use 32 PROTACs with measured passive permeability (given in nm/s) and includes 17 features calculated by RDKit (see [here](https://github.com/brykimjh/degrader-permeability-ml3d-metaD/blob/main/data/calculate_2d_properties.py) for the script they are calculated)\n",
        "\n",
        "The target value is the measured passive permeability that is experimentaly measured.\n",
        "\n",
        "The dataset can be seen here:\n",
        "- https://github.com/brykimjh/degrader-permeability-ml3d-metaD/blob/main/data/2d_features.csv\n",
        "\n",
        "Where the assive permeability is given by `P_app`"
      ],
      "metadata": {
        "id": "aAzSy5lwWyxC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vudPPHEbxOwZ"
      },
      "outputs": [],
      "source": [
        "# Download dataset\n",
        "\n",
        "%%bash\n",
        "dataset_url=\"https://raw.githubusercontent.com/brykimjh/degrader-permeability-ml3d-metaD/refs/heads/main/data/2d_features.csv\"\n",
        "wget ${dataset_url}\n",
        "ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "MrAhw83Cxzw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"2d_features.csv\")"
      ],
      "metadata": {
        "id": "pUY06gC2x_n4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "3j3ouJz8yJ7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.describe()"
      ],
      "metadata": {
        "id": "se-nbCFByMdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(dataset['P_app'],bins=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZINI441oySan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7abmyEGvzuvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1\n",
        "\n",
        "Use the mols2grid package to create a visulazation of all molecules and show the passive permeability on the grid with the correct units."
      ],
      "metadata": {
        "id": "exLbH6dIZjbg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "noJD7sKb0uS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now turn the problem into a classification problem by seperating the molecules into molecules with high permeability and low permeability, by using a cutoff of 7 nm/s that will split the data set equally.\n",
        "\n"
      ],
      "metadata": {
        "id": "DUBh_h0uaSWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Permeable_cutoff = 7.0\n",
        "Low_label = 0\n",
        "High_label = +1\n",
        "Permeable_key_str = f'Permeability High({High_label:})/Low({Low_label:})'\n",
        "dataset[Permeable_key_str] = [High_label if p > Permeable_cutoff else Low_label for p in dataset['P_app']]\n",
        "\n",
        "Number_Permeable_High = np.sum(dataset[Permeable_key_str] == +1)\n",
        "Number_Permeable_Low = np.sum(dataset[Permeable_key_str] == 0)\n",
        "\n",
        "print(\"Key:\",Permeable_key_str)\n",
        "\n",
        "print(\"Number with high permeability (above {:.1f} nm/s): {:d}\".format(Permeable_cutoff,Number_Permeable_High))\n",
        "print(\"Number with low permeability (above {:.1f} nm/s): {:d}\".format(Permeable_cutoff,Number_Permeable_Low))\n",
        "\n",
        "print(\"\")\n",
        "\n",
        "dataset[['P_app', Permeable_key_str] ]"
      ],
      "metadata": {
        "id": "9ehEH7h02xgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a data frame with just the features and target values\n",
        "features = dataset.drop(columns=['Index','Compound','P_app AB (nm/s)','P_app BA (nm/s)','P_app','Smiles', Permeable_key_str])\n",
        "target = dataset[Permeable_key_str]"
      ],
      "metadata": {
        "id": "gRYAXiOi36cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features"
      ],
      "metadata": {
        "id": "jOVV67vYbHCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target"
      ],
      "metadata": {
        "id": "AyWFSgXRbNRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Trees\n",
        "\n",
        "Decision Trees are a simple supervised learning method that can be used for classifcation by creating a tree based on rules that split the dataset into subsets until we get a subset that is only one class.\n",
        "- https://en.wikipedia.org/wiki/Decision_tree_learning\n",
        "- https://scikit-learn.org/stable/modules/tree.html\n",
        "\n",
        "The train tree can then be used to predict. The obtained tree can also be visualized.\n",
        "\n",
        "It is a good idea to visulize the predicted values using a confusion matrix.\n",
        "\n",
        "We then have the\n",
        "- True Positives (TP)\n",
        "- False Positives (FP)\n",
        "- True Negatives (TN)\n",
        "- False Negatives (FN)\n",
        "\n",
        "The choice what is postive and negative is often arbitrary. Here, we consider High Permeability (> 7.0 nm) to be postive. In scikit-learn, the value of +1 is consider as the postive by default.  \n",
        "\n",
        "To measure the performance, we can define different metrics:\n",
        "\n",
        "- Accuracy: (TP+TN) / (TP+TN+FN+FP)\n",
        "- Precision: (TP) / (TP+FP)\n",
        "- Recall: (TP) / (TP+FN)\n",
        "\n",
        "Further information and other performance metrics can be found in the [sklearn manual](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-string-names)\n",
        "\n",
        "[Reminder on the difference between accuracy and precision](https://en.wikipedia.org/wiki/Accuracy_and_precision)\n",
        "\n"
      ],
      "metadata": {
        "id": "YzGctE0Cc03a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "\n",
        "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.5)\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "model.fit(features_train,target_train)\n",
        "\n",
        "target_test_predicted = model.predict(features_test)\n",
        "\n",
        "print(\"Accuracy:                 {:.4f}\".format(metrics.accuracy_score(target_test_predicted,target_test)))\n",
        "print(\"Precision:                {:.4f}\".format(metrics.precision_score(target_test_predicted,target_test)))\n",
        "# print(\"Precision (pos_label=1):  {:.4f}\".format(metrics.precision_score(target_test_predicted,target_test,pos_label=1 )))\n",
        "print(\"Recall:                   {:.4f}\".format(metrics.recall_score(target_test_predicted,target_test)))\n",
        "# print(\"Recall: (pos_label=1)     {:.4f}\".format(metrics.recall_score(target_test_predicted,target_test, pos_label=1 )))\n",
        "\n",
        "\n",
        "\n",
        "tree_plt = plot_tree(model,\n",
        "                     feature_names=features.keys(),\n",
        "                     fontsize=8)\n",
        "cfm = metrics.ConfusionMatrixDisplay.from_predictions(target_test,target_test_predicted)"
      ],
      "metadata": {
        "id": "twX6Gz-H4Qlq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A nicer way to get the tree\n",
        "import graphviz\n",
        "dot_data = export_graphviz(model, out_file=None,\n",
        "                     feature_names=features.keys(),\n",
        "                     filled=True, rounded=True,\n",
        "                     special_characters=True)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph"
      ],
      "metadata": {
        "id": "40uQU8uGOJmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we implement cross validation"
      ],
      "metadata": {
        "id": "PaKlYLbyhQAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_validate,ShuffleSplit\n",
        "\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# Evaluate the models using crossvalidation\n",
        "\n",
        "scoring = {'accuracy':'accuracy',\n",
        "           'recall': 'recall',\n",
        "           'precision':  metrics.make_scorer(metrics.precision_score, zero_division=np.nan)\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# employ 5-fold CV\n",
        "scores_fold = cross_validate(\n",
        "    model,\n",
        "    features, target,\n",
        "    scoring=scoring,\n",
        "    cv=5\n",
        ")\n",
        "\n",
        "# Evaluate the models using crossvalidation\n",
        "NumSplits=1000\n",
        "cv_random = ShuffleSplit(n_splits=NumSplits, test_size=0.5)\n",
        "scores_random = cross_validate(\n",
        "    model,\n",
        "    features, target,\n",
        "    scoring=scoring,\n",
        "    cv=cv_random\n",
        ")\n",
        "\n",
        "print(\"Accuracy\")\n",
        "print(\"- 5-Fold CV                   : {:.3f} +- {:.3f}\".format(scores_fold['test_accuracy'].mean(),scores_fold['test_accuracy'].std()))\n",
        "print(\"- Random Splits ({:d} splits) : {:.3f} +- {:.3f}\".format(NumSplits, scores_random['test_accuracy'].mean(), scores_random['test_accuracy'].std()))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sitaMubb9pd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2\n",
        "\n",
        "Repeat the analysis above using Random Forest\n",
        "- https://scikit-learn.org/stable/modules/ensemble.html#random-forests\n",
        "- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "\n",
        "This is an ensemble method that creates multiple different decision trees, and predicts based on the average. In classification, values will be predicated based on the majority.\n",
        "\n",
        "The hyperparametes in Random Forest is the number of trees. Use the default value of 100 decision trees."
      ],
      "metadata": {
        "id": "06YrNXXVWxUj"
      }
    }
  ]
}