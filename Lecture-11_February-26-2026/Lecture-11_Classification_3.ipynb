{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "generative_ai_disabled": true,
      "authorship_tag": "ABX9TyMCy86skfRPouuVCq4PTiGl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valsson-group/UNT-ChemicalApplicationsOfMachineLearning-Spring2026/blob/main/Lecture-11_February-26-2026/Lecture-11_Classification_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lecture 11 - Classification\n",
        "\n"
      ],
      "metadata": {
        "id": "aAzSy5lwWyxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "MrAhw83Cxzw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we create an example dataset for classifcation with 4 classes."
      ],
      "metadata": {
        "id": "Ww1kdmBba9Dm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "n_classes=4\n",
        "n_samples=1000\n",
        "\n",
        "uneven_classes = False\n",
        "\n",
        "if uneven_classes:\n",
        "  weights=[4, 1, 0.4, 0.1]\n",
        "  weights/=np.sum(weights)\n",
        "else:\n",
        "  weights=None\n",
        "\n",
        "features, target = make_classification(\n",
        "    n_samples=n_samples,\n",
        "    n_features=12,\n",
        "    n_informative=4,\n",
        "    n_redundant=1,\n",
        "    n_repeated=0,\n",
        "    n_classes=n_classes,\n",
        "    shuffle=True,\n",
        "    weights=weights\n",
        ")\n",
        "\n",
        "feature_names = [f\"feature {i}\" for i in range(X.shape[1])]\n",
        "\n",
        "print(\"Size of each class\")\n",
        "for i in range(n_classes):\n",
        "  num = np.sum(target == i)\n",
        "  perc = num/n_samples\n",
        "  print(\"- {:d}: {:d} ({:.1f}%)\".format(i,num,perc*100))"
      ],
      "metadata": {
        "id": "5TaKb_92Z4Fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(target.shape)"
      ],
      "metadata": {
        "id": "Pv40b7xbcL9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "model = RandomForestClassifier(max_depth=2)\n",
        "\n",
        "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2)\n",
        "\n",
        "model.fit(features_train, target_train)\n",
        "\n",
        "target_test_predicted = model.predict(features_test)\n",
        "\n",
        "print(\"Accuracy:                 {:.4f}\".format(metrics.accuracy_score(target_test,target_test_predicted)))\n",
        "print(\"Precision (micro):        {:.4f}\".format(metrics.precision_score(target_test,target_test_predicted,average='micro')))\n",
        "print(\"Precision (macro):        {:.4f}\".format(metrics.precision_score(target_test,target_test_predicted,average='macro')))\n",
        "print(\"Recall (micro):           {:.4f}\".format(metrics.recall_score(target_test,target_test_predicted,average='micro')))\n",
        "print(\"Recall (macro):           {:.4f}\".format(metrics.recall_score(target_test,target_test_predicted,average='macro')))\n",
        "\n",
        "cfm = metrics.ConfusionMatrixDisplay.from_predictions(target_test,target_test_predicted)\n"
      ],
      "metadata": {
        "id": "DKjwOYD4agLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_validate,ShuffleSplit\n",
        "\n",
        "scoring = {'accuracy':'accuracy',\n",
        "            'recall_micro': metrics.make_scorer(metrics.recall_score, zero_division=np.nan, average='micro'),\n",
        "            'precision_micro': metrics.make_scorer(metrics.precision_score, zero_division=np.nan,average='micro'),\n",
        "            'recall_macro': metrics.make_scorer(metrics.recall_score, zero_division=np.nan, average='macro'),\n",
        "            'precision_macro': metrics.make_scorer(metrics.precision_score, zero_division=np.nan,average='macro'),\n",
        "            'roc_auc_ovr': 'roc_auc_ovr',\n",
        "            'roc_auc_ovo': 'roc_auc_ovo'\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "NumSplits=100\n",
        "cv_random = ShuffleSplit(n_splits=NumSplits, test_size=0.2)\n",
        "\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "    # Evaluate the models using crossvalidation\n",
        "scores_random = cross_validate(\n",
        "        model,\n",
        "        features, target,\n",
        "        scoring=scoring,\n",
        "        cv=cv_random,\n",
        "        return_train_score=True,\n",
        "        return_estimator=True,\n",
        "        return_indices=True\n",
        ")\n",
        "\n",
        "print(\"max_depth={:d}\".format(d))\n",
        "print(\"- Accuracy:               {:.3f} +- {:.3f}\".format(scores_random['test_accuracy'].mean(), scores_random['test_accuracy'].std()))\n",
        "print(\"- ROC AUC (OVR, Macro):   {:.3f} +- {:.3f}\".format(scores_random['test_roc_auc_ovr'].mean(), scores_random['test_roc_auc_ovr'].std()))\n",
        "print(\"- ROC AUC (OVO, Macro):   {:.3f} +- {:.3f}\".format(scores_random['test_roc_auc_ovo'].mean(), scores_random['test_roc_auc_ovo'].std()))\n",
        "print(\"- Precision (Micro):      {:.3f} +- {:.3f}\".format(np.nanmean(scores_random['test_precision_micro']), np.nanstd(scores_random['test_precision_micro'])))\n",
        "print(\"- Precision (Macro):      {:.3f} +- {:.3f}\".format(np.nanmean(scores_random['test_precision_macro']), np.nanstd(scores_random['test_precision_macro'])))\n",
        "print(\"- Recall (Micro):         {:.3f} +- {:.3f}\".format(np.nanmean(scores_random['test_precision_micro']), np.nanstd(scores_random['test_precision_micro'])))\n",
        "print(\"- Recall (Macro):         {:.3f} +- {:.3f}\".format(np.nanmean(scores_random['test_precision_macro']), np.nanstd(scores_random['test_precision_macro'])))\n",
        "print(\" \")\n"
      ],
      "metadata": {
        "id": "SRZSFAULzt7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2N1SVA8Mz8Kj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Y-scrambling / Y-randomization"
      ],
      "metadata": {
        "id": "JzC3rUHldGo1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2)\n",
        "\n",
        "scramble = True\n",
        "\n",
        "# this works for numpy arrays\n",
        "rng = np.random.default_rng()\n",
        "target_train_used = rng.choice(target_train, size=target_train.size, replace=False) if scramble else target_train.copy()\n",
        "\n",
        "# if you are using a panda dataframe you should use something like\n",
        "# target_train_used = target_train.sample(frac=1.0).reset_index(drop=True) if scramble else target_train.copy()\n",
        "\n",
        "model.fit(features_train, target_train_used)\n",
        "\n",
        "target_test_predicted = model.predict(features_test)\n",
        "\n",
        "print(\"Accuracy:                 {:.4f}\".format(metrics.accuracy_score(target_test,target_test_predicted)))\n",
        "print(\"Precision (micro):        {:.4f}\".format(metrics.precision_score(target_test,target_test_predicted,average='micro')))\n",
        "print(\"Precision (macro):        {:.4f}\".format(metrics.precision_score(target_test,target_test_predicted,average='macro')))\n",
        "print(\"Recall (micro):           {:.4f}\".format(metrics.recall_score(target_test,target_test_predicted,average='micro')))\n",
        "print(\"Recall (macro):           {:.4f}\".format(metrics.recall_score(target_test,target_test_predicted,average='macro')))\n",
        "\n",
        "cfm = metrics.ConfusionMatrixDisplay.from_predictions(target_test,target_test_predicted)\n"
      ],
      "metadata": {
        "id": "kh-IjOPNdSsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter search by hand\n",
        "\n"
      ],
      "metadata": {
        "id": "VFiQ_b62gOL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_validate,ShuffleSplit\n",
        "\n",
        "scoring = {'accuracy':'accuracy',\n",
        "            'recall_micro': metrics.make_scorer(metrics.recall_score, zero_division=np.nan, average='micro'),\n",
        "            'precision_micro': metrics.make_scorer(metrics.precision_score, zero_division=np.nan,average='micro'),\n",
        "            'recall_macro': metrics.make_scorer(metrics.recall_score, zero_division=np.nan, average='macro'),\n",
        "            'precision_macro': metrics.make_scorer(metrics.precision_score, zero_division=np.nan,average='macro'),\n",
        "            'roc_auc_ovr': 'roc_auc_ovr',\n",
        "            'roc_auc_ovo': 'roc_auc_ovo'\n",
        "}\n",
        "\n",
        "max_depths = [1, 2, 3]\n",
        "\n",
        "NumSplits=100\n",
        "cv_random = ShuffleSplit(n_splits=NumSplits, test_size=0.2)\n",
        "\n",
        "for d in max_depths:\n",
        "    model = RandomForestClassifier(n_estimators=100, max_depth=d)\n",
        "\n",
        "    # Evaluate the models using crossvalidation\n",
        "    scores_random = cross_validate(\n",
        "        model,\n",
        "        features, target,\n",
        "        scoring=scoring,\n",
        "        cv=cv_random,\n",
        "        return_train_score=True,\n",
        "        return_estimator=True,\n",
        "        return_indices=True\n",
        "    )\n",
        "\n",
        "    print(\"max_depth={:d}\".format(d))\n",
        "    print(\"- Accuracy:               {:.3f} +- {:.3f}\".format(scores_random['test_accuracy'].mean(), scores_random['test_accuracy'].std()))\n",
        "    print(\"- ROC AUC (OVR, Macro):   {:.3f} +- {:.3f}\".format(scores_random['test_roc_auc_ovr'].mean(), scores_random['test_roc_auc_ovr'].std()))\n",
        "    print(\"- ROC AUC (OVO, Macro):   {:.3f} +- {:.3f}\".format(scores_random['test_roc_auc_ovo'].mean(), scores_random['test_roc_auc_ovo'].std()))\n",
        "    print(\"- Precision (Micro):      {:.3f} +- {:.3f}\".format(np.nanmean(scores_random['test_precision_micro']), np.nanstd(scores_random['test_precision_micro'])))\n",
        "    print(\"- Precision (Macro):      {:.3f} +- {:.3f}\".format(np.nanmean(scores_random['test_precision_macro']), np.nanstd(scores_random['test_precision_macro'])))\n",
        "    print(\"- Recall (Micro):         {:.3f} +- {:.3f}\".format(np.nanmean(scores_random['test_precision_micro']), np.nanstd(scores_random['test_precision_micro'])))\n",
        "    print(\"- Recall (Macro):         {:.3f} +- {:.3f}\".format(np.nanmean(scores_random['test_precision_macro']), np.nanstd(scores_random['test_precision_macro'])))\n",
        "    print(\" \")\n",
        "\n"
      ],
      "metadata": {
        "id": "XqwmEi86gWt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1xPtOHg_mkf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter search using GridSearchCV"
      ],
      "metadata": {
        "id": "zaVAZMTmmmzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import cross_validate,ShuffleSplit\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "scoring = {'accuracy':'accuracy',\n",
        "            'recall_micro': metrics.make_scorer(metrics.recall_score, zero_division=np.nan, average='micro'),\n",
        "            'precision_micro': metrics.make_scorer(metrics.precision_score, zero_division=np.nan,average='micro'),\n",
        "            'recall_macro': metrics.make_scorer(metrics.recall_score, zero_division=np.nan, average='macro'),\n",
        "            'precision_macro': metrics.make_scorer(metrics.precision_score, zero_division=np.nan,average='macro'),\n",
        "            'roc_auc_ovr': 'roc_auc_ovr',\n",
        "            'roc_auc_ovo': 'roc_auc_ovo'\n",
        "}\n",
        "\n",
        "NumSplits=100\n",
        "cv_random = ShuffleSplit(n_splits=NumSplits, test_size=0.2)\n",
        "\n",
        "\n",
        "parameters = {'max_depth': [2,3,4,5]\n",
        "              }\n",
        "\n",
        "model = RandomForestClassifier(100)\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=model,\n",
        "    param_grid=parameters,\n",
        "    cv=cv_random,\n",
        "    scoring='accuracy',\n",
        ")\n",
        "grid_search.fit(features,target)\n",
        "\n",
        "print(\"Best Params:\", grid_search.best_params_) #\n",
        "print(\"Best Score:\", grid_search.best_score_) #\n"
      ],
      "metadata": {
        "id": "nedUHNJLmmln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search.cv_results_"
      ],
      "metadata": {
        "id": "mYWAjwZzn7vR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Srb28rEoBys"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}